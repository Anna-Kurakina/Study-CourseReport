{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBIKO3kmxJ7Q"
   },
   "source": [
    "# ***Setup***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ghs1oqMbYURm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import platform\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import math\n",
    "import pydot\n",
    "import graphviz\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "suQAO6K0F1nQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.7\n",
      "Tensorflow version: 2.14.0\n"
     ]
    }
   ],
   "source": [
    "print('Python version:', platform.python_version())\n",
    "print('Tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OZHOAwe8_Ad_"
   },
   "outputs": [],
   "source": [
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prFRhqYQxbRD"
   },
   "source": [
    "# ***Prepare the data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YxJ5E9Gewzh7"
   },
   "outputs": [],
   "source": [
    "#number of digits\n",
    "num_classes = 10\n",
    "\n",
    "#Load the dataset MNIST\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# # Normalize data - scale images to the [0, 1] range\n",
    "train_images = tf.keras.utils.normalize(train_images, axis = 1)\n",
    "test_images = tf.keras.utils.normalize(test_images, axis = 1)\n",
    "\n",
    "# # convert class vectors to binary class matrices\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "train_images = train_images.reshape(-1, 28, 28, 1)\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Rs1oKNtpF1nS"
   },
   "outputs": [],
   "source": [
    "# train = pd.read_csv('/content/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8elpZBA09ST3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_images))\n",
    "print(type(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bx1fLbKnwgmJ"
   },
   "source": [
    "# ***Split training and valdiation set***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-_Za4zlsxTxR"
   },
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "J7SCAytG4rCN"
   },
   "outputs": [],
   "source": [
    "# Split the train and the validation set for the fitting\n",
    "train_images, X_val, train_labels, Y_val = train_test_split(train_images, train_labels, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2MRPdckFbYWk"
   },
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(train_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-e-gbJLKxtJN"
   },
   "source": [
    "# ***Create the model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "eExc6PS-_AeA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1606144   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1676266 (6.39 MB)\n",
      "Trainable params: 1676266 (6.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "  [\n",
    "      tf.keras.layers.Input(shape=(28, 28, 1)),\n",
    "      tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding = 'Same'),\n",
    "      tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding = 'Same'),\n",
    "      tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)),\n",
    "      tf.keras.layers.Dropout(0.25),\n",
    "      tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding = 'Same'),\n",
    "      tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding = 'Same'),\n",
    "      tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)),\n",
    "      tf.keras.layers.Dropout(0.25),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "      tf.keras.layers.Dropout(0.5),\n",
    "      tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "  ])\n",
    "\n",
    "# print model layers\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "a6w5HV3QF1nY"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    show_shapes=True,\n",
    "    show_layer_activations=True,\n",
    "    to_file=\"model.png\",\n",
    "    expand_nested=True,\n",
    "    dpi=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "psWRzx6S_AeB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = [tf.keras.metrics.CategoricalAccuracy(name='accuracy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "O_yhuJxT3PgL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of message = b'20        '\n",
      "Recieved the complete info\n",
      "b'20        '\n",
      "['90']\n",
      "=======\n",
      "['90']\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import socket\n",
    "import pickle\n",
    "import rdflib\n",
    "from rdflib import *\n",
    "import plotly.graph_objects as go\n",
    "from rdflib import URIRef, Graph, Namespace\n",
    "from rdflib.plugins.parsers.notation3 import N3Parser\n",
    "from socket import SHUT_RDWR\n",
    "\n",
    "a = 10\n",
    "\n",
    "# Create a socket object and connect to the hostname and port number specified\n",
    "s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "s.connect((socket.gethostname(),1024))\n",
    "\n",
    "# Enter an infinite loop to receive data\n",
    "while True:\n",
    "\t# Initialize variables\n",
    "\tcomplete_info = b''\n",
    "\trec_msg = True\n",
    "\n",
    "\t# Receive data in chunks of 16 bytes until complete data is received\n",
    "\twhile True:\n",
    "\t\tmymsg = s.recv(16)\n",
    "\n",
    "\t\t# Check if the message length has been received\n",
    "\t\tif rec_msg:\n",
    "\t\t\tprint(f\"The length of message = {mymsg[:a]}\")\n",
    "\t\t\tx = int(mymsg[:a])\n",
    "\t\t\trec_msg = False\n",
    "\n",
    "\t\tcomplete_info += mymsg\n",
    "\n",
    "\t\t# Check if the complete data has been received\n",
    "\t\tif len(complete_info)-a == x:\n",
    "\t\t\tprint(\"Recieved the complete info\")\n",
    "\t\t\tprint(complete_info[:a])\n",
    "\n",
    "\t\t\t# Unpickle the received data and store in variable m\n",
    "\t\t\tm = pickle.loads(complete_info[a:])\n",
    "\t\t\tprint(m)\n",
    "\n",
    "\t\t\trec_msg = False\n",
    "\t\t\tcomplete_info = m #b''\n",
    "\t\t\tbreak\n",
    "\n",
    "\t# Print complete_info\n",
    "\tprint(\"=======\")\n",
    "\tprint(complete_info)\n",
    "\n",
    "\t# Break out of the infinite loop\n",
    "\tbreak\n",
    "\n",
    "# Close the socket connection\n",
    "s.close()\n",
    "\n",
    "# Set variable formuladict equal to complete_info\n",
    "accuracy = complete_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xwpNS0Rt3PgM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['90']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgFtOwJtyADZ"
   },
   "source": [
    "# ***Train the model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dxt-0iT8_AeC"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 500\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.CategoricalCrossentropy(), metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_-kGU3PK_AeD"
   },
   "outputs": [],
   "source": [
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                                                               patience=10,\n",
    "                                                               verbose=1,\n",
    "                                                               factor=0.9,\n",
    "                                                               cooldown = 1)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    patience=100,\n",
    "    mode='max',\n",
    "    restore_best_weights=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-WKpu_b9_AeD",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 225/1688 [==>...........................] - ETA: 1:46 - loss: 2.3013 - accuracy: 0.1065"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;66;43;03m# use_multiprocessing=True,\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mlearning_rate_reduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mearly_stopping\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                   \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\NZ\\VenvPython11\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mE:\\NZ\\VenvPython11\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mE:\\NZ\\VenvPython11\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mE:\\NZ\\VenvPython11\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mE:\\NZ\\VenvPython11\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mE:\\NZ\\VenvPython11\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\NZ\\VenvPython11\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mE:\\NZ\\VenvPython11\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mE:\\NZ\\VenvPython11\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32mE:\\NZ\\VenvPython11\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32mE:\\NZ\\VenvPython11\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(datagen.flow(train_images,\n",
    "                    train_labels, batch_size=BATCH_SIZE),\n",
    "                    epochs=EPOCHS,\n",
    "                    shuffle=True,\n",
    "                   # use_multiprocessing=True,\n",
    "                    validation_data=datagen.flow(X_val, Y_val, batch_size=BATCH_SIZE),\n",
    "                    callbacks = [learning_rate_reduction,\n",
    "                    early_stopping\n",
    "                                 ]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0kiCIjb9B1f"
   },
   "source": [
    "# ***Results Visualization***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyjSqEWn9KA4"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title(\"Model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoc\")\n",
    "plt.legend([\"Train\", \"Test\"], loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.savefig('Accuracy.pdf', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLbxEEP09Q58"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Model loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Test\"], loc=(1.03, 0.85))\n",
    "plt.show()\n",
    "plt.savefig('Loss.pdf', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmwzh1T5_AeE"
   },
   "outputs": [],
   "source": [
    "colors=[\"darkred\", \"darkgreen\", \"k\"]\n",
    "\n",
    "def plot_metrics(history):\n",
    "  metrics = ['prc', 'auc', 'loss']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[1], linestyle=\"-\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THXCEh5n_AeE"
   },
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pK8IN_ShyWy5"
   },
   "source": [
    "# ***Evaluate the trained model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlg6jkEuyTSJ"
   },
   "outputs": [],
   "source": [
    "result = model.evaluate(test_images, test_labels, verbose=\"2\")\n",
    "print(\"loss: %.2f%%\"%(result[0]*100))\n",
    "print(\"accuracy: %.2f%%\"%(result[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoFEXnJq3PgP"
   },
   "outputs": [],
   "source": [
    "if int(accuracy) > result[1]*100:\n",
    "    print(\"Try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tIHGB8wy_AeF"
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')\n",
    "#del model  # deletes the existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gL8eXL4a32XG"
   },
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves for training and validation\n",
    "plt.plot(history.history['val_loss'], color='k', label=\"validation loss\")\n",
    "plt.title(\"Test Loss\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('Val.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "luPQfvqj39aE"
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors\n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1)\n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1)\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "# plot the confusion matrix\n",
    "f,ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(confusion_mtx, annot=True, linewidths=1, cmap=\"Greens\", linecolor=\"gray\", fmt= '.0f', ax=ax)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "plt.savefig('Confusion.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lj90pXFM3PgQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEBwF7up3PgQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
