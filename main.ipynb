{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBIKO3kmxJ7Q"
   },
   "source": [
    "# ***Setup***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ghs1oqMbYURm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import platform\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import math\n",
    "import pydot\n",
    "import graphviz\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suQAO6K0F1nQ"
   },
   "outputs": [],
   "source": [
    "print('Python version:', platform.python_version())\n",
    "print('Tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZHOAwe8_Ad_"
   },
   "outputs": [],
   "source": [
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prFRhqYQxbRD"
   },
   "source": [
    "# ***Prepare the data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxJ5E9Gewzh7"
   },
   "outputs": [],
   "source": [
    "#number of digits\n",
    "num_classes = 10\n",
    "\n",
    "#Load the dataset MNIST\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# # Normalize data - scale images to the [0, 1] range\n",
    "train_images = tf.keras.utils.normalize(train_images, axis = 1)\n",
    "test_images = tf.keras.utils.normalize(test_images, axis = 1)\n",
    "\n",
    "# # convert class vectors to binary class matrices\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "train_images = train_images.reshape(-1, 28, 28, 1)\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rs1oKNtpF1nS"
   },
   "outputs": [],
   "source": [
    "# train = pd.read_csv('/content/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8elpZBA09ST3"
   },
   "outputs": [],
   "source": [
    "print(type(train_images))\n",
    "print(type(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bx1fLbKnwgmJ"
   },
   "source": [
    "# ***Split training and valdiation set***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_Za4zlsxTxR"
   },
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7SCAytG4rCN"
   },
   "outputs": [],
   "source": [
    "# Split the train and the validation set for the fitting\n",
    "train_images, X_val, train_labels, Y_val = train_test_split(train_images, train_labels, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2MRPdckFbYWk"
   },
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(train_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-e-gbJLKxtJN"
   },
   "source": [
    "# ***Create the model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eExc6PS-_AeA"
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "  [\n",
    "      tf.keras.layers.Input(shape=(28, 28, 1)),\n",
    "      tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding = 'Same'),\n",
    "      tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding = 'Same'),\n",
    "      tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)),\n",
    "      tf.keras.layers.Dropout(0.25),\n",
    "      tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding = 'Same'),\n",
    "      tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding = 'Same'),\n",
    "      tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)),\n",
    "      tf.keras.layers.Dropout(0.25),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "      tf.keras.layers.Dropout(0.5),\n",
    "      tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "  ])\n",
    "\n",
    "# print model layers\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6w5HV3QF1nY"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    show_shapes=True,\n",
    "    show_layer_activations=True,\n",
    "    to_file=\"model.png\",\n",
    "    expand_nested=True,\n",
    "    dpi=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psWRzx6S_AeB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = [tf.keras.metrics.CategoricalAccuracy(name='accuracy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_yhuJxT3PgL"
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import socket\n",
    "import pickle\n",
    "import rdflib\n",
    "from rdflib import *\n",
    "import plotly.graph_objects as go\n",
    "from rdflib import URIRef, Graph, Namespace\n",
    "from rdflib.plugins.parsers.notation3 import N3Parser\n",
    "from socket import SHUT_RDWR\n",
    "\n",
    "a = 10\n",
    "\n",
    "# Create a socket object and connect to the hostname and port number specified\n",
    "s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "s.connect((socket.gethostname(),1024))\n",
    "\n",
    "# Enter an infinite loop to receive data\n",
    "while True:\n",
    "\t# Initialize variables\n",
    "\tcomplete_info = b''\n",
    "\trec_msg = True\n",
    "\n",
    "\t# Receive data in chunks of 16 bytes until complete data is received\n",
    "\twhile True:\n",
    "\t\tmymsg = s.recv(16)\n",
    "\n",
    "\t\t# Check if the message length has been received\n",
    "\t\tif rec_msg:\n",
    "\t\t\tprint(f\"The length of message = {mymsg[:a]}\")\n",
    "\t\t\tx = int(mymsg[:a])\n",
    "\t\t\trec_msg = False\n",
    "\n",
    "\t\tcomplete_info += mymsg\n",
    "\n",
    "\t\t# Check if the complete data has been received\n",
    "\t\tif len(complete_info)-a == x:\n",
    "\t\t\tprint(\"Recieved the complete info\")\n",
    "\t\t\tprint(complete_info[:a])\n",
    "\n",
    "\t\t\t# Unpickle the received data and store in variable m\n",
    "\t\t\tm = pickle.loads(complete_info[a:])\n",
    "\t\t\tprint(m)\n",
    "\n",
    "\t\t\trec_msg = False\n",
    "\t\t\tcomplete_info = m #b''\n",
    "\t\t\tbreak\n",
    "\n",
    "\t# Print complete_info\n",
    "\tprint(\"=======\")\n",
    "\tprint(complete_info)\n",
    "\n",
    "\t# Break out of the infinite loop\n",
    "\tbreak\n",
    "\n",
    "# Close the socket connection\n",
    "s.close()\n",
    "\n",
    "# Set variable formuladict equal to complete_info\n",
    "accuracy = complete_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwpNS0Rt3PgM"
   },
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgFtOwJtyADZ"
   },
   "source": [
    "# ***Train the model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxt-0iT8_AeC"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 500\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.CategoricalCrossentropy(), metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-kGU3PK_AeD"
   },
   "outputs": [],
   "source": [
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                                                               patience=10,\n",
    "                                                               verbose=1,\n",
    "                                                               factor=0.9,\n",
    "                                                               cooldown = 1)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    patience=100,\n",
    "    mode='max',\n",
    "    restore_best_weights=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-WKpu_b9_AeD",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(datagen.flow(train_images,\n",
    "                    train_labels, batch_size=BATCH_SIZE),\n",
    "                    epochs=EPOCHS,\n",
    "                    shuffle=True,\n",
    "                   # use_multiprocessing=True,\n",
    "                    validation_data=datagen.flow(X_val, Y_val, batch_size=BATCH_SIZE),\n",
    "                    callbacks = [learning_rate_reduction,\n",
    "                    early_stopping\n",
    "                                 ]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0kiCIjb9B1f"
   },
   "source": [
    "# ***Results Visualization***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyjSqEWn9KA4"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title(\"Model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoc\")\n",
    "plt.legend([\"Train\", \"Test\"], loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.savefig('Accuracy.pdf', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLbxEEP09Q58"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Model loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Test\"], loc=(1.03, 0.85))\n",
    "plt.show()\n",
    "plt.savefig('Loss.pdf', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmwzh1T5_AeE"
   },
   "outputs": [],
   "source": [
    "colors=[\"darkred\", \"darkgreen\", \"k\"]\n",
    "\n",
    "def plot_metrics(history):\n",
    "  metrics = ['prc', 'auc', 'loss']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[1], linestyle=\"-\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THXCEh5n_AeE"
   },
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pK8IN_ShyWy5"
   },
   "source": [
    "# ***Evaluate the trained model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlg6jkEuyTSJ"
   },
   "outputs": [],
   "source": [
    "result = model.evaluate(test_images, test_labels, verbose=\"2\")\n",
    "print(\"loss: %.2f%%\"%(result[0]*100))\n",
    "print(\"accuracy: %.2f%%\"%(result[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoFEXnJq3PgP"
   },
   "outputs": [],
   "source": [
    "if int(accuracy) > result[1]*100:\n",
    "    print(\"Try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tIHGB8wy_AeF"
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')\n",
    "#del model  # deletes the existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gL8eXL4a32XG"
   },
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves for training and validation\n",
    "plt.plot(history.history['val_loss'], color='k', label=\"validation loss\")\n",
    "plt.title(\"Test Loss\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('Val.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "luPQfvqj39aE"
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors\n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1)\n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1)\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "# plot the confusion matrix\n",
    "f,ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(confusion_mtx, annot=True, linewidths=1, cmap=\"Greens\", linecolor=\"gray\", fmt= '.0f', ax=ax)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "plt.savefig('Confusion.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lj90pXFM3PgQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEBwF7up3PgQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
